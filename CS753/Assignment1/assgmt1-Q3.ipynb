{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# PART I: Running a SpeechBrain ASR Recipe"
      ],
      "metadata": {
        "id": "p3S0Etz_Nokz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the codebase."
      ],
      "metadata": {
        "id": "bKXIYTJSOnt_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A5H2lpHX7npZ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Clone SpeechBrain repository\n",
        "!git clone https://github.com/Darshan7575/speechbrain.git\n",
        "%cd /content/speechbrain/\n",
        "\n",
        "# Install required dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install SpeechBrain in editable mode\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required imports\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import logging\n",
        "import sys\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import speechbrain as sb\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "from speechbrain.utils.data_utils import get_all_files, download_file\n",
        "from speechbrain.dataio.dataio import read_audio\n",
        "from speechbrain.utils.distributed import run_on_main, if_main_process\n",
        "\n",
        "# Required variables and loggers\n",
        "logger = logging.getLogger(__name__)\n",
        "logger = logging.getLogger(__name__)\n",
        "MINILIBRI_TRAIN_URL = \"http://www.openslr.org/resources/31/train-clean-5.tar.gz\"\n",
        "MINILIBRI_VALID_URL = \"http://www.openslr.org/resources/31/dev-clean-2.tar.gz\"\n",
        "MINILIBRI_TEST_URL = \"https://www.openslr.org/resources/12/test-clean.tar.gz\"\n",
        "SAMPLERATE = 16000\n",
        "\n",
        "device=\"cuda\"\n",
        "run_opts = {'device':device}"
      ],
      "metadata": {
        "id": "61C_gxJo5aRH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer Training\n",
        "In this section, we will train a BPE tokenizer with **150 tokens** using `Sentencepiece`.\n",
        "\n"
      ],
      "metadata": {
        "id": "rtdr1VnyCQTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ############################################################################\n",
        "# Dataset creation helper functions\n",
        "# ############################################################################\n",
        "\n",
        "def prepare_mini_librispeech(\n",
        "    data_folder, save_json_train, save_json_valid, save_json_test\n",
        "):\n",
        "    \"\"\"\n",
        "    Prepares the json files for the Mini Librispeech dataset.\n",
        "    Downloads the dataset if its not found in the `data_folder`.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if this phase is already done (if so, skip it)\n",
        "    if skip(save_json_train, save_json_valid, save_json_test):\n",
        "        logger.info(\"Preparation completed in previous run, skipping.\")\n",
        "        return\n",
        "\n",
        "    # If the dataset doesn't exist yet, download it\n",
        "    train_folder = os.path.join(data_folder, \"LibriSpeech\", \"train-clean-5\")\n",
        "    valid_folder = os.path.join(data_folder, \"LibriSpeech\", \"dev-clean-2\")\n",
        "    test_folder = os.path.join(data_folder, \"LibriSpeech\", \"test-clean\")\n",
        "    if not check_folders(train_folder, valid_folder, test_folder):\n",
        "        download_mini_librispeech(data_folder)\n",
        "\n",
        "    # List files and create manifest from list\n",
        "    logger.info(\n",
        "        f\"Creating {save_json_train}, {save_json_valid}, and {save_json_test}\"\n",
        "    )\n",
        "    extension = [\".flac\"]\n",
        "\n",
        "    # List of flac audio files\n",
        "    wav_list_train = get_all_files(train_folder, match_and=extension)\n",
        "    wav_list_valid = get_all_files(valid_folder, match_and=extension)\n",
        "    wav_list_test = get_all_files(test_folder, match_and=extension)\n",
        "\n",
        "    # List of transcription file\n",
        "    extension = [\".trans.txt\"]\n",
        "    trans_list = get_all_files(data_folder, match_and=extension)\n",
        "    trans_dict = get_transcription(trans_list)\n",
        "\n",
        "    # Create the json files\n",
        "    create_json(wav_list_train, trans_dict, save_json_train)\n",
        "    create_json(wav_list_valid, trans_dict, save_json_valid)\n",
        "    create_json(wav_list_test, trans_dict, save_json_test)\n",
        "\n",
        "\n",
        "def get_transcription(trans_list):\n",
        "    \"\"\"\n",
        "    Returns a dictionary with the transcription of each sentence in the dataset.\n",
        "    \"\"\"\n",
        "    # Processing all the transcription files in the list\n",
        "    trans_dict = {}\n",
        "    for trans_file in trans_list:\n",
        "        # Reading the text file\n",
        "        with open(trans_file) as f:\n",
        "            for line in f:\n",
        "                uttid = line.split(\" \")[0]\n",
        "                text = line.rstrip().split(\" \")[1:]\n",
        "                text = \" \".join(text)\n",
        "                trans_dict[uttid] = text\n",
        "\n",
        "    logger.info(\"Transcription files read!\")\n",
        "    return trans_dict\n",
        "\n",
        "\n",
        "def create_json(wav_list, trans_dict, json_file):\n",
        "    \"\"\"\n",
        "    Creates the json file given a list of wav files and their transcriptions.\n",
        "    \"\"\"\n",
        "    # Processing all the wav files in the list\n",
        "    json_dict = {}\n",
        "    for wav_file in wav_list:\n",
        "\n",
        "        # Reading the signal (to retrieve duration in seconds)\n",
        "        signal = read_audio(wav_file)\n",
        "        duration = signal.shape[0] / SAMPLERATE\n",
        "\n",
        "        # Manipulate path to get relative path and uttid\n",
        "        path_parts = wav_file.split(os.path.sep)\n",
        "        uttid, _ = os.path.splitext(path_parts[-1])\n",
        "        relative_path = os.path.join(\"{data_root}\", *path_parts[-5:])\n",
        "\n",
        "        # Create entry for this utterance\n",
        "        json_dict[uttid] = {\n",
        "            \"wav\": relative_path,\n",
        "            \"length\": duration,\n",
        "            \"words\": trans_dict[uttid],\n",
        "        }\n",
        "\n",
        "    # Writing the dictionary to the json file\n",
        "    with open(json_file, mode=\"w\") as json_f:\n",
        "        json.dump(json_dict, json_f, indent=2)\n",
        "\n",
        "    logger.info(f\"{json_file} successfully created!\")\n",
        "\n",
        "\n",
        "def skip(*filenames):\n",
        "    \"\"\"\n",
        "    Detects if the data preparation has been already done.\n",
        "    If the preparation has been done, we can skip it.\n",
        "    \"\"\"\n",
        "    for filename in filenames:\n",
        "        if not os.path.isfile(filename):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def check_folders(*folders):\n",
        "    \"\"\"Returns False if any passed folder does not exist.\"\"\"\n",
        "    for folder in folders:\n",
        "        if not os.path.exists(folder):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def download_mini_librispeech(destination):\n",
        "    \"\"\"Download dataset and unpack it.\n",
        "    \"\"\"\n",
        "    train_archive = os.path.join(destination, \"train-clean-5.tar.gz\")\n",
        "    valid_archive = os.path.join(destination, \"dev-clean-2.tar.gz\")\n",
        "    test_archive = os.path.join(destination, \"test-clean.tar.gz\")\n",
        "    download_file(MINILIBRI_TRAIN_URL, train_archive)\n",
        "    download_file(MINILIBRI_VALID_URL, valid_archive)\n",
        "    download_file(MINILIBRI_TEST_URL, test_archive)\n",
        "    shutil.unpack_archive(train_archive, destination)\n",
        "    shutil.unpack_archive(valid_archive, destination)\n",
        "    shutil.unpack_archive(test_archive, destination)"
      ],
      "metadata": {
        "id": "ujToJHWC4T5y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_hyperparams = \"\"\"\n",
        "# ############################################################################\n",
        "# Tokenizer: subword BPE with unigram 150\n",
        "# ############################################################################\n",
        "\n",
        "output_folder: !ref results/tokenizer/\n",
        "\n",
        "# Data files\n",
        "data_folder: data\n",
        "train_annotation: !ref <data_folder>/train.json\n",
        "valid_annotation: !ref <data_folder>/valid.json\n",
        "test_annotation: !ref <data_folder>/test.json\n",
        "\n",
        "# Tokenizer training parameters\n",
        "token_type: unigram  # [\"unigram\", \"bpe\", \"char\"]\n",
        "token_output: 150  # index(blank/eos/bos/unk) = 0\n",
        "character_coverage: 1.0\n",
        "json_read: words\n",
        "\n",
        "tokenizer: !name:speechbrain.tokenizers.SentencePiece.SentencePiece\n",
        "   model_dir: !ref <output_folder>\n",
        "   vocab_size: !ref <token_output>\n",
        "   annotation_train: !ref <train_annotation>\n",
        "   annotation_read: !ref <json_read>\n",
        "   annotation_format: json\n",
        "   model_type: !ref <token_type> # [\"unigram\", \"bpe\", \"char\"]\n",
        "   character_coverage: !ref <character_coverage>\n",
        "   annotation_list_to_check: [!ref <train_annotation>, !ref <valid_annotation>]\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rz9pyHan4V0S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load required params from the hyperpyyaml file\n",
        "hparams = load_hyperpyyaml(tokenizer_hyperparams)\n",
        "\n",
        "# 1. Dataset creation\n",
        "\n",
        "## Create experiment directory\n",
        "sb.create_experiment_directory(\n",
        "    experiment_directory=hparams[\"output_folder\"],\n",
        "    overrides=None,\n",
        ")\n",
        "\n",
        "## Create dataset\n",
        "run_on_main(\n",
        "    prepare_mini_librispeech,\n",
        "    kwargs={\n",
        "        \"data_folder\": hparams[\"data_folder\"],\n",
        "        \"save_json_train\": hparams[\"train_annotation\"],\n",
        "        \"save_json_valid\": hparams[\"valid_annotation\"],\n",
        "        \"save_json_test\": hparams[\"test_annotation\"],\n",
        "    },\n",
        ")\n",
        "\n",
        "# 2. Tokenizer training\n",
        "hparams[\"tokenizer\"]()\n",
        "\n",
        "# 3. Saving tokenizer in .ckpt extension\n",
        "output_path = hparams[\"output_folder\"]\n",
        "token_output = hparams[\"token_output\"]\n",
        "token_type = hparams[\"token_type\"]\n",
        "bpe_model = f\"{output_path}/{token_output}_{token_type}.model\"\n",
        "tokenizer_ckpt = f\"{output_path}/tokenizer.ckpt\"\n",
        "shutil.copyfile(bpe_model, tokenizer_ckpt)"
      ],
      "metadata": {
        "id": "nA8xD6Do4Xl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "35bcda3a-5509-4b08-b2c6-596d65303efd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/tokenizer/\n",
            "Downloading http://www.openslr.org/resources/31/train-clean-5.tar.gz to data/train-clean-5.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train-clean-5.tar.gz: 333MB [00:19, 16.8MB/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://www.openslr.org/resources/31/dev-clean-2.tar.gz to data/dev-clean-2.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "dev-clean-2.tar.gz: 126MB [00:08, 14.1MB/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.openslr.org/resources/12/test-clean.tar.gz to data/test-clean.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test-clean.tar.gz: 347MB [00:21, 16.4MB/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__main__ - Creating data/train.json, data/valid.json, and data/test.json\n",
            "__main__ - Transcription files read!\n",
            "__main__ - data/train.json successfully created!\n",
            "__main__ - data/valid.json successfully created!\n",
            "__main__ - data/test.json successfully created!\n",
            "speechbrain.tokenizers.SentencePiece - Train tokenizer with type:unigram\n",
            "speechbrain.tokenizers.SentencePiece - Extract words sequences from:data/train.json\n",
            "speechbrain.tokenizers.SentencePiece - Text file created at: results/tokenizer/train.txt\n",
            "speechbrain.tokenizers.SentencePiece - ==== Loading Tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer path: results/tokenizer/150_unigram.model\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer vocab_size: 150\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer type: unigram\n",
            "speechbrain.tokenizers.SentencePiece - ==== Accuracy checking for recovering text from tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - recover words from: data/train.json\n",
            "speechbrain.tokenizers.SentencePiece - Wrong recover words: 0\n",
            "speechbrain.tokenizers.SentencePiece - accuracy recovering words: 1.0\n",
            "speechbrain.tokenizers.SentencePiece - ==== Accuracy checking for recovering text from tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - recover words from: data/valid.json\n",
            "speechbrain.tokenizers.SentencePiece - Wrong recover words: 0\n",
            "speechbrain.tokenizers.SentencePiece - accuracy recovering words: 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'results/tokenizer//tokenizer.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\n",
        "In this section, we will train a **6 layer Conformer** encoder only architecture with the `CTC objective`."
      ],
      "metadata": {
        "id": "vwqFx3QcOdd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_hyperparams = \"\"\"\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
        "seed: 2024\n",
        "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
        "\n",
        "# Data files\n",
        "data_folder: data\n",
        "train_annotation: !ref <data_folder>/train.json\n",
        "valid_annotation: !ref <data_folder>/valid.json\n",
        "test_annotation:  !ref <data_folder>/test.json\n",
        "\n",
        "# Language model (LM) pretraining\n",
        "pretrained_lm_tokenizer_path: ./results/tokenizer\n",
        "\n",
        "# Training parameters\n",
        "number_of_epochs: 30\n",
        "batch_size: 8\n",
        "lr_adam: 0.001\n",
        "max_grad_norm: 5.0\n",
        "ckpt_interval_minutes: 15 # save checkpoint every N min\n",
        "loss_reduction: 'batchmean'\n",
        "\n",
        "# Dataloader options\n",
        "train_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "valid_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "test_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "# Feature parameters\n",
        "sample_rate: 16000\n",
        "n_fft: 400\n",
        "n_mels: 80\n",
        "\n",
        "####################### Model parameters ###########################\n",
        "# Transformer\n",
        "d_model: 128\n",
        "nhead: 4\n",
        "num_encoder_layers: 6\n",
        "d_ffn: 512\n",
        "transformer_dropout: 0.1\n",
        "activation: !name:torch.nn.GELU\n",
        "output_neurons: 150\n",
        "label_smoothing: 0.0\n",
        "attention_type: RelPosMHAXL\n",
        "\n",
        "# Outputs\n",
        "blank_index: 0\n",
        "pad_index: 0\n",
        "bos_index: 1\n",
        "eos_index: 2\n",
        "\n",
        "# Decoding parameters\n",
        "min_decode_ratio: 0.0\n",
        "max_decode_ratio: 1.0\n",
        "test_beam_size: 1\n",
        "ctc_weight_decode: 1.0\n",
        "\n",
        "############################## models ################################\n",
        "\n",
        "compute_features: !new:speechbrain.lobes.features.Fbank\n",
        "    sample_rate: !ref <sample_rate>\n",
        "    n_fft: !ref <n_fft>\n",
        "    n_mels: !ref <n_mels>\n",
        "\n",
        "CNN: !new:speechbrain.lobes.models.convolution.ConvolutionFrontEnd\n",
        "    input_shape: (8, 10, 80)\n",
        "    num_blocks: 2\n",
        "    num_layers_per_block: 1\n",
        "    out_channels: (64, 32)\n",
        "    kernel_sizes: (3, 3)\n",
        "    strides: (2, 2)\n",
        "    residuals: (False, False)\n",
        "\n",
        "# standard parameters for the BASE model\n",
        "Transformer: !new:speechbrain.lobes.models.transformer.TransformerASR.TransformerASR\n",
        "    input_size: 640\n",
        "    tgt_vocab: !ref <output_neurons>\n",
        "    d_model: !ref <d_model>\n",
        "    nhead: !ref <nhead>\n",
        "    num_encoder_layers: !ref <num_encoder_layers>\n",
        "    num_decoder_layers: 0\n",
        "    d_ffn: !ref <d_ffn>\n",
        "    dropout: !ref <transformer_dropout>\n",
        "    activation: !ref <activation>\n",
        "    encoder_module: conformer\n",
        "    attention_type: !ref <attention_type>\n",
        "    normalize_before: True\n",
        "\n",
        "tokenizer: !new:sentencepiece.SentencePieceProcessor\n",
        "\n",
        "ctc_lin: !new:speechbrain.nnet.linear.Linear\n",
        "    input_size: !ref <d_model>\n",
        "    n_neurons: !ref <output_neurons>\n",
        "\n",
        "normalize: !new:speechbrain.processing.features.InputNormalization\n",
        "    norm_type: global\n",
        "    update_until_epoch: 4\n",
        "\n",
        "modules:\n",
        "    CNN: !ref <CNN>\n",
        "    Transformer: !ref <Transformer>\n",
        "    ctc_lin: !ref <ctc_lin>\n",
        "    normalize: !ref <normalize>\n",
        "\n",
        "model: !new:torch.nn.ModuleList\n",
        "    - [!ref <CNN>, !ref <Transformer>, !ref <ctc_lin>]\n",
        "\n",
        "# define two optimizers here for two-stage training\n",
        "Adam: !name:torch.optim.Adam\n",
        "    lr: !ref <lr_adam>\n",
        "    betas: (0.9, 0.98)\n",
        "    eps: 0.000000001\n",
        "\n",
        "log_softmax: !new:torch.nn.LogSoftmax\n",
        "    dim: -1\n",
        "\n",
        "ctc_cost: !name:speechbrain.nnet.losses.ctc_loss\n",
        "    blank_index: !ref <blank_index>\n",
        "    reduction: !ref <loss_reduction>\n",
        "\n",
        "noam_annealing: !new:speechbrain.nnet.schedulers.NoamScheduler\n",
        "    lr_initial: !ref <lr_adam>\n",
        "    n_warmup_steps: 1500\n",
        "\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "error_rate_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats\n",
        "\n",
        "cer_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats\n",
        "   split_tokens: True\n",
        "\n",
        "# The pretrainer allows a mapping between pretrained files and instances that\n",
        "# are declared in the yaml. E.g here, we will download the file tokenizer.ckpt\n",
        "# and it will be loaded into \"tokenizer\" which is pointing to the <pretrained_lm_tokenizer_path> defined\n",
        "# before.\n",
        "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
        "    loadables:\n",
        "        tokenizer: !ref <tokenizer>\n",
        "    paths:\n",
        "        tokenizer: !ref <pretrained_lm_tokenizer_path>/tokenizer.ckpt\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6WPcwXueCRm7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataio_prepare(hparams):\n",
        "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
        "    It also defines the data processing pipeline through user-defined functions.\n",
        "    \"\"\"\n",
        "    # Define audio pipeline. In this case, we simply read the path contained\n",
        "    # in the variable wav with the audio reader.\n",
        "    @sb.utils.data_pipeline.takes(\"wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"sig\")\n",
        "    def audio_pipeline(wav):\n",
        "        \"\"\"Load the audio signal. This is done on the CPU in the `collate_fn`.\"\"\"\n",
        "        sig = sb.dataio.dataio.read_audio(wav)\n",
        "        return sig\n",
        "\n",
        "    tokenizer = hparams[\"tokenizer\"]\n",
        "    # Define text processing pipeline. We start from the raw text and then\n",
        "    # encode it using the tokenizer. The tokens with BOS are used for feeding\n",
        "    # decoder during training, the tokens with EOS for computing the cost function.\n",
        "    # The tokens without BOS or EOS is for computing CTC loss.\n",
        "    @sb.utils.data_pipeline.takes(\"words\")\n",
        "    @sb.utils.data_pipeline.provides(\n",
        "        \"wrd\", \"tokens_list\", \"tokens_bos\", \"tokens_eos\", \"tokens\"\n",
        "    )\n",
        "    def text_pipeline(wrd):\n",
        "        \"\"\"Processes the transcriptions to generate proper labels\"\"\"\n",
        "        yield wrd\n",
        "        tokens_list = tokenizer.encode_as_ids(wrd)\n",
        "        yield tokens_list\n",
        "        tokens_bos = torch.LongTensor([hparams[\"bos_index\"]] + (tokens_list))\n",
        "        yield tokens_bos\n",
        "        tokens_eos = torch.LongTensor(tokens_list + [hparams[\"eos_index\"]])\n",
        "        yield tokens_eos\n",
        "        tokens = torch.LongTensor(tokens_list)\n",
        "        yield tokens\n",
        "\n",
        "    # Define datasets from json data manifest file\n",
        "    # Define datasets sorted by ascending lengths for efficiency\n",
        "    datasets = {}\n",
        "    data_folder = hparams[\"data_folder\"]\n",
        "    for dataset in [\"train\", \"valid\", \"test\"]:\n",
        "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
        "            json_path=hparams[f\"{dataset}_annotation\"],\n",
        "            replacements={\"data_root\": data_folder},\n",
        "            dynamic_items=[audio_pipeline, text_pipeline],\n",
        "            output_keys=[\n",
        "                \"id\",\n",
        "                \"sig\",\n",
        "                \"wrd\",\n",
        "                \"tokens_bos\",\n",
        "                \"tokens_eos\",\n",
        "                \"tokens\",\n",
        "            ],\n",
        "        )\n",
        "        hparams[f\"{dataset}_dataloader_opts\"][\"shuffle\"] = False\n",
        "\n",
        "    datasets[\"train\"] = datasets[\"train\"].filtered_sorted(sort_key=\"length\")\n",
        "    hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
        "\n",
        "    return (\n",
        "        datasets[\"train\"],\n",
        "        datasets[\"valid\"],\n",
        "        datasets[\"test\"],\n",
        "        tokenizer\n",
        "    )"
      ],
      "metadata": {
        "id": "euJMqDLSWv7Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training procedure\n",
        "class BaseASR(sb.Brain):\n",
        "    def __init__(\n",
        "        self,\n",
        "        modules=None,\n",
        "        opt_class=None,\n",
        "        hparams=None,\n",
        "        run_opts=None,\n",
        "        checkpointer=None,\n",
        "        profiler=None,\n",
        "        tokenizer=None,\n",
        "    ):\n",
        "        super(BaseASR, self).__init__(\n",
        "            modules=modules,\n",
        "            opt_class=opt_class,\n",
        "            hparams=hparams,\n",
        "            run_opts=run_opts,\n",
        "            checkpointer=checkpointer,\n",
        "            profiler=profiler\n",
        "        )\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Performs a forward pass through the encoder\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        wavs, wav_lens = batch.sig\n",
        "        tokens_bos, _ = batch.tokens_bos\n",
        "\n",
        "        # compute features\n",
        "        feats = self.hparams.compute_features(wavs) ##Chinmay\n",
        "        current_epoch = self.hparams.epoch_counter.current\n",
        "        feats = self.modules.normalize(feats, wav_lens, epoch=current_epoch)\n",
        "\n",
        "        # forward modules\n",
        "        src = self.modules.CNN(feats)\n",
        "\n",
        "        enc_out, _ = self.modules.Transformer(\n",
        "            src, tokens_bos, wav_lens, pad_idx=self.hparams.pad_index,\n",
        "        )\n",
        "\n",
        "        # output layer for ctc log-probabilities\n",
        "        logits = self.modules.ctc_lin(enc_out)\n",
        "        p_ctc = self.hparams.log_softmax(logits) ##Chinmay\n",
        "\n",
        "        # Compute outputs\n",
        "        hyps = None\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            hyps = None\n",
        "        else:\n",
        "            hyps = sb.decoders.ctc_greedy_decode(\n",
        "                p_ctc, wav_lens, blank_id=self.hparams.blank_index\n",
        "            )\n",
        "\n",
        "        return p_ctc, wav_lens, hyps\n",
        "\n",
        "    def get_ctc_probs(self, batch):\n",
        "        batch = batch.to(self.device)\n",
        "        wavs, wav_lens = batch.sig\n",
        "        tokens_bos, _ = batch.tokens_bos\n",
        "\n",
        "        # compute features\n",
        "        feats = self.hparams.compute_features(wavs) #Chinmay\n",
        "        current_epoch = self.hparams.epoch_counter.current\n",
        "        feats = self.modules.normalize(feats, wav_lens, epoch=current_epoch)\n",
        "\n",
        "        # forward modules\n",
        "        src = self.modules.CNN(feats)\n",
        "\n",
        "        enc_out, _ = self.modules.Transformer(\n",
        "            src, tokens_bos, wav_lens, pad_idx=self.hparams.pad_index,\n",
        "        )\n",
        "\n",
        "        logits = self.modules.ctc_lin(enc_out)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the CTC loss given predictions and targets.\"\"\"\n",
        "\n",
        "        (p_ctc, wav_lens, hyps,) = predictions\n",
        "\n",
        "        ids = batch.id\n",
        "        tokens_eos, tokens_eos_lens = batch.tokens_eos\n",
        "        tokens, tokens_lens = batch.tokens\n",
        "\n",
        "        # Calculate CTC loss\n",
        "        loss = self.hparams.ctc_cost(p_ctc, tokens, wav_lens, tokens_lens).sum() ##Chinmay\n",
        "\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            # Decode token terms to words\n",
        "            predicted_words = [\n",
        "                self.tokenizer.decode_ids(utt_seq).split(\" \") for utt_seq in hyps\n",
        "            ]\n",
        "            target_words = [wrd.split(\" \") for wrd in batch.wrd]\n",
        "            self.wer_metric.append(ids, predicted_words, target_words)\n",
        "            self.cer_metric.append(ids, predicted_words, target_words)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_evaluate_start(self, max_key=None, min_key=None):\n",
        "        \"\"\"Performs checkpoint averge if needed\"\"\"\n",
        "        super().on_evaluate_start()\n",
        "\n",
        "        ckpts = self.checkpointer.find_checkpoints(\n",
        "            max_key=max_key, min_key=min_key\n",
        "        )\n",
        "        ckpt = sb.utils.checkpoints.average_checkpoints(\n",
        "            ckpts, recoverable_name=\"model\", device=self.device\n",
        "        )\n",
        "\n",
        "        self.hparams.model.load_state_dict(ckpt, strict=True)\n",
        "        self.hparams.model.eval()\n",
        "        print(\"Loaded the average\")\n",
        "\n",
        "    def evaluate_batch(self, batch, stage):\n",
        "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
        "        with torch.no_grad():\n",
        "            predictions = self.compute_forward(batch, stage=stage)\n",
        "            loss = self.compute_objectives(predictions, batch, stage=stage)\n",
        "        return loss.detach()\n",
        "\n",
        "    def on_stage_start(self, stage, epoch):\n",
        "        \"\"\"Gets called at the beginning of each epoch\"\"\"\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            self.cer_metric = self.hparams.cer_computer()\n",
        "            self.wer_metric = self.hparams.error_rate_computer()\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
        "        # Compute/store important stats\n",
        "        stage_stats = {\"loss\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_stats = stage_stats\n",
        "        else:\n",
        "            stage_stats[\"CER\"] = self.cer_metric.summarize(\"error_rate\")\n",
        "            stage_stats[\"WER\"] = self.wer_metric.summarize(\"error_rate\")\n",
        "\n",
        "        # log stats and save checkpoint at end-of-epoch\n",
        "        if stage == sb.Stage.VALID and sb.utils.distributed.if_main_process():\n",
        "\n",
        "            lr = self.hparams.noam_annealing.current_lr\n",
        "            steps = self.optimizer_step\n",
        "            optimizer = self.optimizer.__class__.__name__\n",
        "\n",
        "            epoch_stats = {\n",
        "                \"epoch\": epoch,\n",
        "                \"lr\": lr,\n",
        "                \"steps\": steps,\n",
        "                \"optimizer\": optimizer,\n",
        "            }\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta=epoch_stats,\n",
        "                train_stats=self.train_stats,\n",
        "                valid_stats=stage_stats,\n",
        "            )\n",
        "            # Save only last 10 checkpoints\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta={\"loss\": stage_loss, \"epoch\": epoch},\n",
        "                max_keys=[\"epoch\"],\n",
        "                num_to_keep=10,\n",
        "            )\n",
        "\n",
        "        elif stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats=stage_stats,\n",
        "            )\n",
        "            # Write the WER metric for test dataset\n",
        "            if if_main_process():\n",
        "                with open(self.hparams.test_wer_file, \"w\") as w:\n",
        "                    self.wer_metric.write_stats(w)\n",
        "\n",
        "    def fit_batch(self, batch):\n",
        "        \"\"\"Performs a forward + backward pass on 1 batch\n",
        "        \"\"\"\n",
        "\n",
        "        should_step = self.step % self.grad_accumulation_factor == 0\n",
        "\n",
        "        outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
        "        loss = self.compute_objectives(outputs, batch, sb.Stage.TRAIN)\n",
        "        loss.backward()\n",
        "        if self.check_gradients(loss):\n",
        "            self.optimizer.step()\n",
        "        self.zero_grad()\n",
        "        self.optimizer_step += 1\n",
        "        self.hparams.noam_annealing(self.optimizer)\n",
        "\n",
        "        self.on_fit_batch_end(batch, outputs, loss, should_step)\n",
        "        return loss.detach().cpu()"
      ],
      "metadata": {
        "id": "wUEBBUOQZ4V-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_hyperparameters = \"\"\"\n",
        "# Setup the directory to host experiment results\n",
        "output_folder: !ref results/transformer/Task_1\n",
        "wer_file: !ref <output_folder>/wer.txt\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        model: !ref <model>\n",
        "        noam_scheduler: !ref <noam_annealing>\n",
        "        normalizer: !ref <normalize>\n",
        "        counter: !ref <epoch_counter>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DDQEQ8M2MNAi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = global_hyperparams + task_hyperparameters\n",
        "hparams = load_hyperpyyaml(hyperparams)\n",
        "\n",
        "# Create experiment directory\n",
        "sb.create_experiment_directory(\n",
        "    experiment_directory=hparams[\"output_folder\"],\n",
        "    overrides=None,\n",
        ")\n",
        "\n",
        "# Here we create the datasets objects as well as tokenization and encoding\n",
        "(\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    test_data,\n",
        "    tokenizer\n",
        ") = dataio_prepare(hparams)\n",
        "\n",
        "# We download the pretrained LM from HuggingFace (or elsewhere depending on\n",
        "# the path given in the YAML file). The tokenizer is loaded at the same time.\n",
        "run_on_main(hparams[\"pretrainer\"].collect_files)\n",
        "hparams[\"pretrainer\"].load_collected(device=run_opts[\"device\"])\n",
        "\n",
        "# Trainer initialization\n",
        "asr_brain = BaseASR(\n",
        "    modules=hparams[\"modules\"],\n",
        "    opt_class=hparams[\"Adam\"],\n",
        "    hparams=hparams,\n",
        "    checkpointer=hparams[\"checkpointer\"],\n",
        "    run_opts=run_opts,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# adding objects to trainer:\n",
        "train_dataloader_opts = hparams[\"train_dataloader_opts\"]\n",
        "valid_dataloader_opts = hparams[\"valid_dataloader_opts\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "tGonNC7u8hlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e2ac0e-ccc6-4ede-aea7-5406176676e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/transformer/Task_1\n",
            "speechbrain.pretrained.fetching - Destination tokenizer.ckpt: local file in /content/speechbrain/results/tokenizer/tokenizer.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Set local path in self.paths[tokenizer] = model_checkpoints/tokenizer.ckpt\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: tokenizer\n",
            "speechbrain.utils.parameter_transfer - Redirecting (loading from local path): model_checkpoints/tokenizer.ckpt -> model_checkpoints/tokenizer.ckpt\n",
            "speechbrain.core - Info: max_grad_norm arg from hparam file is used\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 2.6M trainable parameters in BaseASR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "asr_brain.fit(\n",
        "    asr_brain.hparams.epoch_counter,\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    train_loader_kwargs=train_dataloader_opts,\n",
        "    valid_loader_kwargs=valid_dataloader_opts\n",
        ")\n",
        "\n",
        "# Testing\n",
        "asr_brain.hparams.test_wer_file = asr_brain.hparams.wer_file\n",
        "asr_brain.evaluate(\n",
        "    train_data,\n",
        "    max_key=\"epoch\",\n",
        "    test_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW9PuacXgG7Y",
        "outputId": "d9a59cb5-2d09-4912-be42-9240055e521b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:40<00:00,  4.72it/s, train_loss=474]\n",
            "100%|██████████| 137/137 [00:09<00:00, 14.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 1, lr: 1.26e-04, steps: 190, optimizer: Adam - train loss: 4.74e+02 - valid loss: 2.35e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-16-03+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.92it/s, train_loss=431]\n",
            "100%|██████████| 137/137 [00:09<00:00, 14.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 2, lr: 2.53e-04, steps: 380, optimizer: Adam - train loss: 4.31e+02 - valid loss: 2.34e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-16-39+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:29<00:00,  6.54it/s, train_loss=430]\n",
            "100%|██████████| 137/137 [00:09<00:00, 14.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 3, lr: 3.79e-04, steps: 570, optimizer: Adam - train loss: 4.30e+02 - valid loss: 2.32e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-17-18+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.84it/s, train_loss=410]\n",
            "100%|██████████| 137/137 [00:10<00:00, 12.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 4, lr: 5.06e-04, steps: 760, optimizer: Adam - train loss: 4.10e+02 - valid loss: 2.09e+02, valid CER: 82.49, valid WER: 95.55\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-17-56+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 190/190 [00:27<00:00,  6.92it/s, train_loss=352]\n",
            "100%|██████████| 137/137 [00:12<00:00, 11.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 5, lr: 6.33e-04, steps: 950, optimizer: Adam - train loss: 3.52e+02 - valid loss: 1.78e+02, valid CER: 70.80, valid WER: 93.12\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-18-36+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 190/190 [00:28<00:00,  6.70it/s, train_loss=307]\n",
            "100%|██████████| 137/137 [00:12<00:00, 10.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 6, lr: 7.59e-04, steps: 1140, optimizer: Adam - train loss: 3.07e+02 - valid loss: 1.60e+02, valid CER: 62.95, valid WER: 91.45\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-19-18+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 190/190 [00:28<00:00,  6.77it/s, train_loss=273]\n",
            "100%|██████████| 137/137 [00:13<00:00, 10.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 7, lr: 8.86e-04, steps: 1330, optimizer: Adam - train loss: 2.73e+02 - valid loss: 1.45e+02, valid CER: 56.32, valid WER: 87.90\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-19-59+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.83it/s, train_loss=245]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 8, lr: 9.94e-04, steps: 1520, optimizer: Adam - train loss: 2.45e+02 - valid loss: 1.34e+02, valid CER: 51.01, valid WER: 85.63\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-20-42+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.95it/s, train_loss=220]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 9, lr: 9.37e-04, steps: 1710, optimizer: Adam - train loss: 2.20e+02 - valid loss: 1.25e+02, valid CER: 46.91, valid WER: 84.42\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-21-24+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.79it/s, train_loss=199]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 10, lr: 8.89e-04, steps: 1900, optimizer: Adam - train loss: 1.99e+02 - valid loss: 1.19e+02, valid CER: 43.71, valid WER: 82.38\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-22-08+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.93it/s, train_loss=181]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 11, lr: 8.47e-04, steps: 2090, optimizer: Adam - train loss: 1.81e+02 - valid loss: 1.15e+02, valid CER: 43.11, valid WER: 80.70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-22-50+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-16-03+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.85it/s, train_loss=167]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 12, lr: 8.11e-04, steps: 2280, optimizer: Adam - train loss: 1.67e+02 - valid loss: 1.12e+02, valid CER: 41.48, valid WER: 79.72\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-23-33+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-16-39+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.80it/s, train_loss=153]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 13, lr: 7.79e-04, steps: 2470, optimizer: Adam - train loss: 1.53e+02 - valid loss: 1.10e+02, valid CER: 40.12, valid WER: 78.51\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-24-17+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-17-18+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.90it/s, train_loss=142]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 14, lr: 7.51e-04, steps: 2660, optimizer: Adam - train loss: 1.42e+02 - valid loss: 1.09e+02, valid CER: 39.69, valid WER: 77.95\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-25-00+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-17-56+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:28<00:00,  6.73it/s, train_loss=132]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 15, lr: 7.26e-04, steps: 2850, optimizer: Adam - train loss: 1.32e+02 - valid loss: 1.07e+02, valid CER: 38.50, valid WER: 76.90\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-25-44+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-18-36+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.79it/s, train_loss=122]\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 16, lr: 7.03e-04, steps: 3040, optimizer: Adam - train loss: 1.22e+02 - valid loss: 1.07e+02, valid CER: 37.72, valid WER: 75.96\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-26-28+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-19-18+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.86it/s, train_loss=114]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 17, lr: 6.82e-04, steps: 3230, optimizer: Adam - train loss: 1.14e+02 - valid loss: 1.07e+02, valid CER: 37.14, valid WER: 75.54\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-27-12+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-19-59+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.79it/s, train_loss=106]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 18, lr: 6.62e-04, steps: 3420, optimizer: Adam - train loss: 1.06e+02 - valid loss: 1.08e+02, valid CER: 36.91, valid WER: 75.60\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-27-55+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-20-42+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.85it/s, train_loss=99]\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 19, lr: 6.45e-04, steps: 3610, optimizer: Adam - train loss: 99.04 - valid loss: 1.07e+02, valid CER: 36.27, valid WER: 74.50\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-28-40+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-21-24+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.93it/s, train_loss=92.9]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 20, lr: 6.28e-04, steps: 3800, optimizer: Adam - train loss: 92.93 - valid loss: 1.10e+02, valid CER: 36.66, valid WER: 74.49\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-29-23+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-22-08+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.80it/s, train_loss=86.9]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 21, lr: 6.13e-04, steps: 3990, optimizer: Adam - train loss: 86.89 - valid loss: 1.10e+02, valid CER: 36.21, valid WER: 73.96\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-30-07+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-22-50+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.87it/s, train_loss=81.3]\n",
            "100%|██████████| 137/137 [00:17<00:00,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 22, lr: 5.99e-04, steps: 4180, optimizer: Adam - train loss: 81.33 - valid loss: 1.12e+02, valid CER: 35.79, valid WER: 73.83\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-30-52+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-23-33+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.90it/s, train_loss=77.4]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 23, lr: 5.86e-04, steps: 4370, optimizer: Adam - train loss: 77.41 - valid loss: 1.14e+02, valid CER: 35.81, valid WER: 73.58\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-31-36+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-24-17+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:28<00:00,  6.75it/s, train_loss=72.3]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 24, lr: 5.74e-04, steps: 4560, optimizer: Adam - train loss: 72.30 - valid loss: 1.15e+02, valid CER: 35.70, valid WER: 73.30\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-32-20+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-25-00+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.85it/s, train_loss=68.2]\n",
            "100%|██████████| 137/137 [00:17<00:00,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 25, lr: 5.62e-04, steps: 4750, optimizer: Adam - train loss: 68.24 - valid loss: 1.16e+02, valid CER: 35.22, valid WER: 72.52\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-33-05+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-25-44+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:28<00:00,  6.57it/s, train_loss=64.4]\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 26, lr: 5.51e-04, steps: 4940, optimizer: Adam - train loss: 64.40 - valid loss: 1.16e+02, valid CER: 35.09, valid WER: 72.12\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-33-51+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-26-28+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:28<00:00,  6.75it/s, train_loss=60.9]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 27, lr: 5.41e-04, steps: 5130, optimizer: Adam - train loss: 60.91 - valid loss: 1.18e+02, valid CER: 34.81, valid WER: 72.62\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-34-36+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-27-12+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.79it/s, train_loss=57.7]\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 28, lr: 5.31e-04, steps: 5320, optimizer: Adam - train loss: 57.69 - valid loss: 1.21e+02, valid CER: 35.01, valid WER: 72.70\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-35-20+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-27-55+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.89it/s, train_loss=54.3]\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 29, lr: 5.22e-04, steps: 5510, optimizer: Adam - train loss: 54.26 - valid loss: 1.23e+02, valid CER: 35.25, valid WER: 73.13\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-36-05+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-28-40+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:27<00:00,  6.91it/s, train_loss=51.9]\n",
            "100%|██████████| 137/137 [00:16<00:00,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 30, lr: 5.13e-04, steps: 5700, optimizer: Adam - train loss: 51.94 - valid loss: 1.24e+02, valid CER: 34.83, valid WER: 73.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-36-49+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+18-29-23+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/transformer/Task_1/save/CKPT+2024-02-17+18-36-49+00\n",
            "Loaded the average\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:42<00:00,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - Epoch loaded: 30 - test loss: 28.81, test CER: 6.10, test WER: 20.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.810358750977"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART III: Visualizing CTC alignments"
      ],
      "metadata": {
        "id": "JbkMK32DJpHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "(\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    test_data,\n",
        "    _\n",
        ") = dataio_prepare(hparams)\n",
        "\n",
        "#Creating a test dataloader to get model results on test audio\n",
        "hparams['train_dataloader_opts']['batch_size'] = 8\n",
        "test_loader = asr_brain.make_dataloader(test_data, sb.Stage.TEST, **hparams[\"train_dataloader_opts\"])\n",
        "results = None\n",
        "\n",
        "#Creating a batch for the test dataloader and getting model results\n",
        "for batch in test_loader:\n",
        "    ground_truth_tokens = batch.tokens[0]\n",
        "    target_lens = (ground_truth_tokens != 0).sum(-1)\n",
        "    _, input_lens = batch.sig\n",
        "    results = asr_brain.compute_forward(batch, sb.Stage.TEST)[0]\n",
        "    input_lens = torch.round(input_lens * results.shape[1]).to(torch.int)\n",
        "    break\n",
        "print(results.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "zIfWCEVTJvYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82721445-3e43-4172-8328-6537a267631b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 538, 150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def logadd(x0, x1, x2):\n",
        "\t# produces nan gradients in backward if -inf log-space zero element is used https://github.com/pytorch/pytorch/issues/31829\n",
        "\treturn torch.logsumexp(torch.stack([x0, x1, x2]), dim = 0)"
      ],
      "metadata": {
        "id": "9b4G2mMaBzsV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install einops"
      ],
      "metadata": {
        "id": "YzLrDWqMFBOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c6ad9f1-09d6-4c83-8aa5-41a19f45d596"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import rearrange\n",
        "def ctc_alignment(log_probs : torch.Tensor, targets : torch.Tensor, input_lengths : torch.Tensor, target_lengths : torch.Tensor, blank : int = 0):\n",
        "    '''\n",
        "    this function computes the ctc-alignment matrix, then performs a backward-algorithm\n",
        "    pass on it to find the best state sequence (states being the transformer states here).\n",
        "    the ctc-algorithm equations can be found on the 3rd slide of the following link -\n",
        "    https://www.cse.iitb.ac.in/~pjyothi/cs753/slides/lecture15.pdf\n",
        "    keep in mind that the equations are 1-indexed while our implementation is 0-indexed\n",
        "    '''\n",
        "    max_input_len, batch_size, num_tokens = log_probs.shape\n",
        "    _, max_target_len = targets.shape\n",
        "\n",
        "    batch_arange = torch.arange(batch_size, device = input_lengths.device)\n",
        "    # print(\"Targets: \", targets.shape)\n",
        "    # print(\"Batch size:\", batch_size)\n",
        "    # print(\"Max Target Len:\", max_target_len)\n",
        "    ##############################\n",
        "    # TODO(1) - add \"_\" (blank) token alternatively to target sequence (starting and ending with \"_\")\n",
        "    # example - \"a man saw a cat\" should become \"_a_ _m_a_n_ _s_a_w_ _a_ _c_a_t_\"\n",
        "    # (assuming that each character is one token; a token might be >1 characters long)\n",
        "    # if the original sequence had L tokens, `padded_targets` should now have 2*L+1 tokens\n",
        "     ### Complete this ##Chinmay\n",
        "    # padded_targets = torch.stack((torch.full_like(targets, blank), targets), dim=2).view(batch_size, max_target_len)\n",
        "    # print(padded_targets.shape)\n",
        "    # # padded_targets = padded_targets.view(batch_size, max_target_len)\\\n",
        "    # # .t().contiguous().view(batch_size, max_target_len)\n",
        "    # print(padded_targets.shape)\n",
        "    # padded_targets = torch.cat([padded_targets, torch.full_like(torch.empty((batch_size, 1)), blank)], dim = 1)\n",
        "    padded_targets = rearrange([torch.full_like(targets, blank), targets], ' t h w -> h (w t)')\n",
        "    padded_targets = torch.cat([padded_targets, torch.full_like(torch.empty((batch_size, 1)), blank)], dim = 1)\n",
        "    ##############################\n",
        "    #print(padded_targets.shape)\n",
        "    padded_targets = padded_targets.long()\n",
        "    assert padded_targets.shape == (batch_size, 2 * max_target_len + 1)\n",
        "\n",
        "    #print(padded_targets.dtype)\n",
        "    # Compute positions where target[j] != target[j-2]\n",
        "    diff_labels = torch.cat([\n",
        "        torch.as_tensor([[False, False]], device = targets.device).expand(len(batch_arange), -1),\n",
        "        padded_targets[:, 2:] != padded_targets[:, :-2]\n",
        "    ], dim = 1)\n",
        "    #print(diff_labels[1])\n",
        "\n",
        "    # Gather log-probs per input sequence index for tokens in target sequence\n",
        "    log_probs_for_targets = log_probs.gather(-1, padded_targets.unsqueeze(0).repeat(max_input_len, 1, 1))\n",
        "    assert log_probs_for_targets.shape == (max_input_len, batch_size, max_target_len * 2 + 1)\n",
        "\n",
        "\n",
        "    # To avoid nan grad in torch.logsumexp\n",
        "    min_element = torch.finfo(log_probs.dtype).min\n",
        "\n",
        "    # Padding is required at the start of log_alpha for vectorization\n",
        "    # Allows using torch.where for the i=j-2 step of ctc alignment computation\n",
        "    zero_padding = 2\n",
        "\n",
        "    # `log_alpha` is the ctc-probability matrix\n",
        "    # We want to deal in the logarithm-space since the probabilities can end up\n",
        "    # becoming very small and naive multiplication of small numbers can be imprecise.\n",
        "    # Note that usual-multiplication -> log-addition.\n",
        "    # Also note the utility of `logadd` function\n",
        "    log_alpha = torch.full(\n",
        "        size = (max_input_len, batch_size, zero_padding + padded_targets.shape[-1]),\n",
        "        fill_value = min_element, device = log_probs.device, dtype = log_probs.dtype\n",
        "    )\n",
        "\n",
        "    ##############################\n",
        "    # TODO(2) - initialization of ctc-probability matrix\n",
        "    # alpha[0] is non-zero only for first blank (\"_\") and first non-blank token\n",
        "    log_alpha[0, :, zero_padding + 0] = log_probs_for_targets[0, :, 0] ##CHinmay\n",
        "    log_alpha[0, :, zero_padding + 1] = log_probs_for_targets[0, :, 1] ##Chinmay\n",
        "    ##############################\n",
        "\n",
        "    # iterate over input sequence\n",
        "    for t in range(1, max_input_len):\n",
        "        ##############################\n",
        "        # TODO(3) - compute updates using indices j, j-1, j-2; refer to slides\n",
        "        # note that updates for j-2 are conditional upon y[j-2] != y[j], use torch.where\n",
        "        # with a suitable boolean tensor defined above\n",
        "        # update_j =  log_alpha[t - 1, :,zero_padding: ]\n",
        "        # update_j_minus_1 = log_alpha[t - 1, :, zero_padding:]\n",
        "        # update_j_minus_2 = torch.where(diff_labels, log_alpha[t - 1, :, zero_padding:], 0)\n",
        "        update_j = log_alpha[t-1, :, zero_padding:]\n",
        "        update_j_minus_1 = log_alpha[t-1, :, zero_padding-1:-1]\n",
        "        update_j_minus_2 = torch.where(diff_labels, log_alpha[t-1, :, zero_padding-2:-2], torch.full_like(log_alpha[t-1, :, zero_padding-2:-2], fill_value = min_element)) # using min_element for -inf = log(zero)\n",
        "        ##############################\n",
        "\n",
        "        # multiplying with probability is equiv. to adding in the log space\n",
        "        log_alpha[t, :, zero_padding:] = logadd(\n",
        "            update_j,\n",
        "            update_j_minus_1,\n",
        "            update_j_minus_2\n",
        "        ) + log_probs_for_targets[t]\n",
        "\n",
        "    ##############################\n",
        "    # TODO(4) - compute ctc loss terms\n",
        "    # refer to slides, the CTC(x, y) equation - loss is from time step T, tokens 2l, 2l+1\n",
        "    # T might be different for different sequences, use `input_lengths` for that\n",
        "    # l might be different for different sequences, use `target_lengths` for that\n",
        "    # print(\"Input lenghts: \", input_lengths)\n",
        "    # print(\"Target lengths: \", target_lengths)\n",
        "    # print(\"log_alpha: \", log_alpha.shape)\n",
        "    abc = log_alpha[input_lengths - 1, batch_arange].\\\n",
        "    gather( -1, torch.stack([zero_padding + target_lengths * 2 - 1, zero_padding + target_lengths * 2], dim = -1))\n",
        "    ctc_loss_term = torch.exp(abc)\n",
        "    ### Complete this computation. You will likely need to define\n",
        "    ### new helper variables to help with this computation.\n",
        "    ##############################\n",
        "    assert ctc_loss_term.shape == (batch_size, 2)\n",
        "\n",
        "    # `path` stores the best hidden state sequence\n",
        "    path = torch.zeros(max_input_len, batch_size, device = log_alpha.device, dtype = torch.int64)\n",
        "\n",
        "    # at timestep T, best index is 2l or 2l+1\n",
        "    path[input_lengths - 1, batch_arange] = zero_padding + 2 * target_lengths - 1 + ctc_loss_term.argmax(dim = -1)\n",
        "\n",
        "    for t, indices in reversed(list(enumerate(path))[1:]):\n",
        "        ##############################\n",
        "        # TODO(5) - compute possible previous states given the current best states in `indices`\n",
        "        # previous states could come from transition i->j where i can be j, j-1 or j-2 (if y[j] != y[j-2])\n",
        "        # if y[j] == y[j-2], use 0 as possible previous state; since 0 is a padding state,\n",
        "        # log_alpha will be very low and argmax below would take care of it.\n",
        "        # such tricks to handle corner-cases help vectorize code in a better fashion.\n",
        "        #print(\"Diff_labels: \",diff_labels[batch_arange, (indices - zero_padding)] )\n",
        "        possible_previous_states =  torch.stack([(indices - 2) * diff_labels[batch_arange, (indices - zero_padding).clamp(min = 0)],\\\n",
        "                                                 (indices - 1).clamp(min = 0), indices], dim = -1)\n",
        "        ##############################\n",
        "        assert possible_previous_states.shape == (batch_size, 3)\n",
        "\n",
        "        # get best possible previous state\n",
        "        argmax_among_prev_states = log_alpha[t - 1, batch_arange].gather(-1, possible_previous_states).argmax(dim = -1)\n",
        "        path[t - 1] += (indices - 2 + argmax_among_prev_states).clamp(min = 0)\n",
        "\n",
        "    # color correct (input_index, target_index) cell\n",
        "    # `highlighted_best_path` is a binary (0-1) matrix\n",
        "    highlighted_best_path = torch.zeros_like(log_alpha).scatter_(\n",
        "        dim = -1,\n",
        "        index = path.unsqueeze(-1),\n",
        "        value = 1.0\n",
        "    )[..., (zero_padding + 1):]\n",
        "\n",
        "    # compute unpadded best path\n",
        "    # `highlighted_best_path` can have blank's (\"_\"), we want a mapping to the non-blank tokens only\n",
        "    # (assumed convention) when removing padding, we assign a blank token's positions to the previous token;\n",
        "    # note that the foremost blank token has already been removed above\n",
        "    unpadded_best_path = highlighted_best_path.reshape(max_input_len, batch_size, max_target_len, 2).sum(-1)\n",
        "    assert unpadded_best_path.shape == (max_input_len, batch_size, max_target_len)\n",
        "\n",
        "    return unpadded_best_path"
      ],
      "metadata": {
        "id": "gBADwCu24x3L"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing CTC alignments using the model results\n",
        "results_in = results.cpu().transpose(0,1)\n",
        "alignment = ctc_alignment(results_in, ground_truth_tokens, input_lens, target_lens, blank = 0)\n",
        "alignment = alignment[:,0 , :target_lens[0]]\n",
        "\n",
        "print(alignment.shape)\n"
      ],
      "metadata": {
        "id": "KBHYK7so-G2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25548a90-fcc3-4933-a299-55201df2b43f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([538, 34])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer is an object of the SentencePieceProcessor class,\n",
        "# Create an array of all the tokens of tokenizer, arranged according to their token IDs\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Get the total number of tokens in the model\n",
        "def array_of_all_tokens(tokenizer):\n",
        "  num_tokens = tokenizer.get_piece_size()\n",
        "\n",
        "  all_tokens_and_ids = [(tokenizer.id_to_piece(token_id), token_id) for token_id in range(num_tokens)]\n",
        "  all_token=[]\n",
        "  for token, token_id in all_tokens_and_ids:\n",
        "      all_token.append(token)\n",
        "  all_tokens=np.array(all_token)\n",
        "  return all_tokens\n"
      ],
      "metadata": {
        "id": "wGXi20uxgO9N"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# TODO(6) -  Plot the alignments of the output tokens of the model and the input audio signal\n",
        "# For this, use the ctc_alignments function and the array of all tokens previously created\n",
        "############################\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import seaborn as sns\n",
        "def plotting(test_data,all_tokens):\n",
        "  # Returns nothing, displays plot (save as image CTCalignments.png)\n",
        "  # Uses alignment computed two cells back\n",
        "      fig, ax = plt.subplots(figsize=(10, 8))\n",
        "      yticklabels = all_tokens[test_data[0]['tokens']]\n",
        "\n",
        "      # Create the heatmap plot\n",
        "      sns.heatmap(alignment.t(), cmap='rocket', yticklabels=yticklabels, annot=False)\n",
        "\n",
        "      # Decorate the plot\n",
        "      plt.xlabel('Input Audio')\n",
        "      plt.ylabel('Tokens')\n",
        "      plt.title('CTC Alignment between the audio and tokens')\n",
        "\n",
        "      # Show the plot\n",
        "      #plt.show()\n",
        "      plt.savefig('CTCalignments.png')\n",
        "      files.download('CTCalignments.png')\n",
        "\n",
        "      # Refer to the provided image in the assignment pdf for reference"
      ],
      "metadata": {
        "id": "eLwAC5qeYm2M"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_gt(tokenizer,ground_truth_tokens):\n",
        "  print(ground_truth_tokens[0])\n",
        "  print(tokenizer.decode([int(x) for x in ground_truth_tokens[0]]))"
      ],
      "metadata": {
        "id": "GM0TUMWkDIeD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens=array_of_all_tokens(tokenizer)\n",
        "plotting(test_data,all_tokens)\n",
        "print_gt(tokenizer,ground_truth_tokens)"
      ],
      "metadata": {
        "id": "EE3Fzy_P0934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967
        },
        "outputId": "d4cad303-9488-4c8a-8fd5-aae8973b9b06"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_28acb2c0-5951-41cd-94df-e6a8268ad086\", \"CTCalignments.png\", 43250)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([120,   7,  82,   4,   9,   1,  35,  47,  82,  57,  29,  26,  22,  90,\n",
            "         62,  16, 110,  11,  12, 145,   2,   1,  12,  50, 127,  31,   8,  69,\n",
            "          8,  24,  26, 112,  29,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0])\n",
            "ALL THE TIME HE WAS TALKING TO ME HIS ANGRY LITTLE EYES WERE FOLLOWING LAKE ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Replace 'folder_path' with the path of the folder you want to download\n",
        "folder_path = '/content/speechbrain/results/transformer/Task_1/save/CKPT+2024-02-17+18-36-49+00'\n",
        "shutil.make_archive('/content/task3_model_Checkpoints', 'zip', folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RrCfNSgWiQaa",
        "outputId": "ad51a1e3-50c1-47ab-f984-ecd63679c8a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/task3_model_Checkpoints.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/task3_model_Checkpoints.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uF0nGe-5iLd4",
        "outputId": "2edf2e3d-32b8-4951-af86-e755d8a45139"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_02e2348f-da61-4239-abe8-cdefd619e18b\", \"task3_model_Checkpoints.zip\", 29085597)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}